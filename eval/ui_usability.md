1. [Characterization of Quality Attributes to Evaluate the User Experience in Augmented Reality (2022)](https://ieeexplore.ieee.org/document/9928275)
* Shortlisted studies meeting quality criteria: **101** (IEEE: 32, SCOPUS: 52, ACM: 17), focusing on AR concepts, UX criteria, trends, and challenges.
* The study emphasizes that despite efforts by organizations like IEEE to create AR standards, the issue of user experience **(UX) in AR has not been addressed comprehensively**.
* UI usability assessment in augmented reality (AR) utilizes tools like **QUIS** and **SGUS** questionnaire for user satisfaction. 
* User experience evaluation involves questionnaires such as **UEQ** and **SUS**.
* AR UIs **face unique challenges** due to real-world factors such as lighting, shadow, distance, and precision, which necessitate careful design and evaluation.
* AR developers should focus on **designing intuitive and minimal UI**, as well as optimizing user input methods for better engagement. 
* The authors used the Delphi Method with experts to categorize UX attributes in AR apps. While their focus was on overall experience, they noted that some UX aspects, like emotional impact and engagement, **can be influenced by the usability and design of the UI**.

2. [Interactive Robotic Plastering: Augmented Interactive Design and Fabrication for On-site Robotic Plastering (2022)](https://dl.acm.org/doi/10.1145/3491102.3501842)
* UI usability
* A questionnaire was developed based on the Post-Study System Usability Questionnaire **(PSSUQ)** model.
* **Extended with additional questions** about the abstractness of visualization and the audio cues of the guidance system. 
* **7-point Likert scale** for scoring (1 - strongly agree, 7 - strongly disagree).
* The questionnaire aimed to evaluate usability across multiple dimensions: Overall score, System Usefulness (SYSUSE), Information Quality (INFOQUAL), Interface Quality (INTERQUAL).
* **Open-ended comments** section in the questionnaire allowed participants to provide additional insights
* The survey was conducted **anonymously** to encourage honest and unbiased responses.
* The evaluation involved **expert users**, both designers and skilled workers, who were knowledgeable in the field.
* Participants were **encouraged to think aloud** and share opinions while interacting with the system's UI.
* Observations **noted participants' behavior** changes, learning curves, and interactions with the UI elements.

3. [Lean Manufacturing and Ergonomics Integration: Defining Productivity and Wellbeing Indicators in a Human–Robot Workstation (2021)](https://www.researchgate.net/publication/349260427_Lean_Manufacturing_and_Ergonomics_Integration_Defining_Productivity_and_Wellbeing_Indicators_in_a_Human-Robot_Workstation)
* UX usability
* The questionnaire is structured into **several categories**: (A)Characterization of Population, (B)Robotics, (C)Self-Reported Physical Exertion, (D)Global Assessment of Workstation
* **Likert Scale** (0—No opinion; 1—Total disagreement; 2—Disagreement; 3—Neutral; 4—Some agreement; 5—Totally agree) is used in Categories B and D
* **CR-10 Scale**: used in Category (C) 
* The sample size is limited to **four workers** due to company constraints.
* The questionnaire is applied twice: first, **before** the collaborative workstation implementation (categories A and B), and then **after** the installation (full questionnaire including categories A, B, C, and D).
* Workers have the opportunity to provide **open comments** and suggestions if the available options don't fully capture their perceptions.

4. [AR-based interaction for human–robot (2020)](https://www.sciencedirect.com/science/article/pii/S0736584519307355)
* UX/UI usability
* They measured two **performance metrics**: (Average total task execution time, Average total robot idle time)
* **Questionnaire** (13 template questions) to evaluate their experience with the systems. 
* **Likert Scale** (from 1 (totally disagree) to 5 (totally agree))
* **Open comments**
* **20 university students** who volunteered for the study.
* Through both quantitative and qualitative analysis, the researchers assessed the safety, ergonomics, task understanding, and overall usability of the three systems.

5. [Augmented bricklaying (2020)](https://link.springer.com/article/10.1007/s41693-020-00035-8)
* UI usability
* Paper questionnaire based on the Questionnaire for User Interface Satisfaction (**QUIS**) model, 14 questions
* 10-point **Likert-type scale**
* Two groups evaluated: experienced construction **workers and novices**.
* Survey taken **anonymously and in solitude**.
* **Voiced opinions and comments** made by users while using the system were noted.
* **Learning curve** of novices' performance improvement over time.
* **Comparison between users with and without assistance** during system use.

6. [Empowering assembly workers with cognitive disabilities by working with collaborative robots: a study to capture design requirements (2019)](https://www.sciencedirect.com/science/article/pii/S2212827119305074)
* UX/UI usability
* **Observational Studies** (observed how the worker with disabilities interacted with the prototype system)
* One **expert with cognitive disabilities**

7. [The Design and Evaluation of an Ergonomic Contactless Gesture Control System for Industrial Robots (2018)](https://www.researchgate.net/publication/325151765_The_Design_and_Evaluation_of_an_Ergonomic_Contactless_Gesture_Control_System_for_Industrial_Robots)
* UI usability
* System Usability questionnaire (**SUS**)
* 7-point **Likert scale** ("Strongly Disagree" to "Strongly Agree.")
* The SUS included statements related to three ergonomic **criteria**: physical workload, intuitiveness, and enjoyableness. 
* **Eight participants**, included both males and females, with varying levels of experience in robot control.
* Participants received a 5-minute **training session**.

8. [Digital Human Models in Human Factors and Ergonomics Evaluation of Gesture Interfaces (2018)](https://dl.acm.org/doi/10.1145/3229088)
* UX/UI usability
* Case 2 Computer-Vision-Based System discusses more about UI
* **Open-Ended Questions** (The qualitative feedback about naturalness, mistakes/errors, and other aspects might have been collected through open-ended questions in the questionnaire.)
* **Nine research scientists** (5 males and 4 females) took part in this case. Average age was 36 years (age range: 29–57 yrs.). All participants were right-handed.

9. [Assessing Instructions in Augmented Reality for Human-robot Collaborative Assembly by Using Demonstrators (2017)](https://www.sciencedirect.com/science/article/pii/S221282711730135X)
* UI usability
* System Usability questionnaire (**SUS**) , 10 questions in Swedish
* **Likert-scale** questions
* During each assembly task, a test assistant **noted instances when the test-persons asked for help** or deviated from the AR interface's instructions.
* **Four groups** of high-school students from local technical schools were used as test-groups (15-17 years old).
* The participants were divided into **two categories** within each group: 
  * **Assembly Group**: Some participants were selected as volunteers to perform the assembly task using the Augmented Reality (AR) interface.
  * **Observing Group**: The remaining participants observed the test-persons (assembly volunteers) and interacted with them, despite being discouraged.

